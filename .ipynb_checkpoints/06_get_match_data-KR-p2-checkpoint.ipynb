{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bc87dc-6950-43aa-9705-eafaad313179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import date, datetime, timedelta, timezone\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import yaml\n",
    "from itertools import chain\n",
    "\n",
    "import concurrent.futures\n",
    "from threading import Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a2c473-37dc-4eea-ab6f-b1281d715ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/17 23:10:31 WARN Utils: Your hostname, LAPTOP-4O0SI9BK resolves to a loopback address: 127.0.1.1; using 172.25.8.93 instead (on interface eth0)\n",
      "25/02/17 23:10:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/17 23:10:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/02/17 23:10:32 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n",
      "/usr/local/lib/python3.10/dist-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "appName = \"PySpark TFT puuids\"\n",
    "master = \"local[*]\"\n",
    "conf = SparkConf() \\\n",
    "    .setAppName(appName) \\\n",
    "    .setMaster(master) \\\n",
    "    .set(\"spark.executor.memory\", \"40g\") \\\n",
    "    .set(\"spark.driver.memory\", \"40g\") \\\n",
    "    .set(\"spark.executor.memoryOverhead\", \"8g\") \\\n",
    "    .set(\"spark.local.dir\", \"/home/mai/spark-temp\") \\\n",
    "    .set(\"spark.sql.session.timeZone\", \"UTC\") \\\n",
    "    .set(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .set(\"spark.dynamicAllocation.minExecutors\", \"2\") \\\n",
    "    .set(\"spark.dynamicAllocation.maxExecutors\", \"50\") \\\n",
    "    .set(\"spark.speculation\", \"true\") \n",
    "   \n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = sqlContext.sparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8746d3f4-b005-4371-a442-97bb6c07ebed",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ada7fd-b2a8-4401-98f5-710d22063a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./api_key.yaml', 'r') as file:\n",
    "    API_KEY = yaml.safe_load(file)['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20aeecdf-1b23-4638-988c-c4051defac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY = 'RGAPI-b3773734-23bc-4d27-8b55-bed5ea5c103d'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16930c-6541-427d-89a8-4c7902526442",
   "metadata": {},
   "source": [
    "## Get match data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6f2640b-63d2-4d65-8042-1f5c54c69bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'kr'\n",
    "REGION_TO_EXECUTE = 'ASIA'\n",
    "BASE_URL = f'https://{REGION_TO_EXECUTE}.api.riotgames.com/tft/match/v1/matches'\n",
    "TIER = 'GOLD'\n",
    "DIVISION = 'I'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3854fe9a-0068-451f-9d79-00b4299a01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the match id\n",
    "# df = spark.read.parquet(f'./data/tft_matches_id/match_id_{REGION}_{TIER}_{DIVISION}.parquet')\n",
    "# # exclude = spark.read.parquet(f'./data/tft_matches_id/match_id_{REGION}_CHALLENGER_{DIVISION}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f4662d6-8ad7-4552-97fa-c6d8f06849bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a9d8cdd-4ce5-4792-b038-22e05192cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter out the match ids already existing in challenger ranked players match history\n",
    "# df = df.join(exclude, on=['match_id'], how='leftanti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b98c5dd6-54c5-4199-82e5-b61c1103270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f20940-d5a5-46b4-9b39-20e9bd5406fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_ids = [row['match_id'] for row in df.select('match_id').collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f78f6c00-ac57-4e40-9db6-f213135962c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(match_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85dff25d-3648-41b0-b319-352539790071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_ids_1 = match_ids[:7000]\n",
    "# match_ids_2 = match_ids[7000:14000]\n",
    "# match_ids_3 = match_ids[14000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ad5aba-b23a-41ef-a03a-9a851d205af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save into 2 parts\n",
    "# pd.DataFrame(match_ids_1, columns=['match_id']).to_parquet(f'./data/tft_matches_id/match_id_{REGION}_{TIER}_{DIVISION}_p1.parquet', index=False)\n",
    "# pd.DataFrame(match_ids_2, columns=['match_id']).to_parquet(f'./data/tft_matches_id/match_id_{REGION}_{TIER}_{DIVISION}_p2.parquet', index=False)\n",
    "# pd.DataFrame(match_ids_3, columns=['match_id']).to_parquet(f'./data/tft_matches_id/match_id_{REGION}_{TIER}_{DIVISION}_p3.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01f52e61-f431-49ee-b0b4-16332ace9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ids_3 = pd.read_parquet(f'./data/tft_matches_id/match_id_{REGION}_{TIER}_{DIVISION}_p3.parquet')['match_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5281b6-8fe4-4444-b23a-3734a7e155e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7256"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(match_ids_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6e4cc01-eeb8-479c-9e88-faa9512928e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limits\n",
    "MAX_WORKERS = 20\n",
    "REQS_PER_SEC = 20\n",
    "REQS_PER_2MIN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5472531-8bfc-49c4-809f-3a67f7ae90ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global counters\n",
    "request_counter = 0\n",
    "lock = Lock()          # ensure thread safety for counter updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f15fde4-f0ed-4f11-adad-82a95632d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a global session\n",
    "session = requests.Session()\n",
    "session.headers.update({\"X-Riot-Token\": API_KEY,\n",
    "                       'Connection': 'keep-alive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13ab1ff3-6d2e-4e72-9995-2913512f555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_data(match_id, max_retries=5):\n",
    "    global request_counter\n",
    "    # construct url\n",
    "    url = f'{BASE_URL}/{match_id}'\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = session.get(url, timeout=10)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "            elif response.status_code == 429:  # Rate limit exceeded\n",
    "                retry_after = int(response.headers.get(\"Retry-After\", 5))\n",
    "                # print(f\"Rate limit exceeded. Waiting {retry_after} seconds...\")\n",
    "                time.sleep(retry_after)\n",
    "            else:\n",
    "                print(f\"Error {response.status_code}: {response.text}\")\n",
    "                return None\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            # print(f\"Connection error: {e}. Retrying in {2 ** attempt} seconds...\")\n",
    "            time.sleep(2 ** attempt)  # Exponential backoff\n",
    "\n",
    "        # response = session.get(url)\n",
    "        # if response.status_code == 200:\n",
    "        #     # Update request counter safely\n",
    "        #     with lock:\n",
    "        #         request_counter += 1\n",
    "        #     return response.json()\n",
    "        # elif response.status_code == 429:   # rate limit hit\n",
    "        #     retry_after = int(response.headers.get('Retry-After', 2))\n",
    "        #     # print(f\"Rate limit exceeded. Waiting {retry_after} seconds...\")\n",
    "        #     time.sleep(retry_after)\n",
    "        # else:\n",
    "        #     print(f\"Error {response.status_code} for match {match_id}: {response.text}\")\n",
    "        #     return None  # Skip failed requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c34412a4-cdc7-4305-8c96-17c8adb68360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_data_parallel(match_ids_):\n",
    "    global request_counter\n",
    "    match_data = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = []\n",
    "        for i, match_id in enumerate(match_ids_):\n",
    "            futures.append(executor.submit(get_match_data, match_id))  # Correct function call\n",
    "            \n",
    "            # Rate limit handling\n",
    "            if (i + 1) % REQS_PER_SEC == 0:\n",
    "                print(f\"Reached {REQS_PER_SEC} requests, sleeping 1 second...\")\n",
    "                time.sleep(1)\n",
    "            if (i + 1) % REQS_PER_2MIN == 0:\n",
    "                print(f\"Reached {REQS_PER_2MIN} requests, sleeping 120 seconds...\")\n",
    "                time.sleep(120)\n",
    "\n",
    "        results = [future.result() for future in futures]  # Get results\n",
    "    return [data for data in results if data is not None]  # Filter out failed requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5441a-b3b4-49d7-918c-39cb9b62c567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 100 requests, sleeping 120 seconds...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 100 requests, sleeping 120 seconds...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 100 requests, sleeping 120 seconds...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 100 requests, sleeping 120 seconds...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 100 requests, sleeping 120 seconds...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 20 requests, sleeping 1 second...\n",
      "Reached 100 requests, sleeping 120 seconds...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "match_data = get_match_data_parallel(match_ids_3[3600:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f07f91-cc30-4bd4-809c-78da2add5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(match_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edff032-2226-4826-99fa-ed6a12e99d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(match_data).explode('info.participants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137f787-af7f-4632-9c85-7f5f0ed49ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99cef0-847b-4759-8e66-c4dd1ea39bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc787e2-ae5f-4bf2-b5c6-ca8938872863",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['info.queueId'] == 1100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e89c9-af47-4e5f-9bdb-dd30d338ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to parquet\n",
    "match_df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b14bbe-fa5a-46de-b9a6-09b7cc7f0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.write.mode('overwrite').parquet(f'./data/tft_match_data/matches_{REGION}_{TIER}_{DIVISION}_p4.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca5fa5-56a0-40f8-b61a-2e37c269ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(f'./data/tft_match_data_pandas/matches_{REGION}_{TIER}_{DIVISION}_p4.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472220b-a9ea-4690-8aca-65f0d7611bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
